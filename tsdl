#!/bin/bash
# tsdl - Download TS segments from an HLS playlist and combine them into a video,
#       while tracking and displaying the total downloaded size in-place.

# Usage: tsdl <URL> [output_file_path]
if [[ -z "$1" ]]; then
    echo "Usage: $0 <URL> [output_file_path]"
    exit 1
fi

URL="$1"

# Determine output file path; if not provided, default to ./downloads/output.mp4
if [[ -n "$2" ]]; then
    OUTPUT_PATH="$2"
else
    OUTPUT_DIR="./downloads"
    mkdir -p "$OUTPUT_DIR"
    OUTPUT_PATH="$OUTPUT_DIR/output.mp4"
fi

# Validate extension
if [[ ! "$OUTPUT_PATH" =~ \.(mp4|MP4|mkv|MKV|avi|AVI|mov|MOV|flv|FLV)$ ]]; then
    echo "Error: The output file must have a valid video extension."
    exit 1
fi

# Names & temp dir
OUTPUT_DIR=$(dirname "$OUTPUT_PATH")
OUTPUT_FILENAME=$(basename "$OUTPUT_PATH")
OUTPUT_NAME="${OUTPUT_FILENAME%.*}"
TMP_DIR="${OUTPUT_PATH}.temp"
mkdir -p "$TMP_DIR"
STATE_FILE="$TMP_DIR/${OUTPUT_NAME}_state.txt"
PLAYLIST_CACHE="$TMP_DIR/playlist_url.txt"
MAX_RETRIES=10

# 1) Resume state
TOTAL_BYTES=0
COMPLETED_FILES=0
if [[ -f "$STATE_FILE" ]]; then
    COMPLETED_FILES=$(<"$STATE_FILE")
    echo "Resuming from file #$COMPLETED_FILES..."
    for ((i=1; i<=COMPLETED_FILES; i++)); do
        f="$TMP_DIR/${OUTPUT_NAME}_part_${i}.ts"
        # Check if the file exists before trying to get its size
        if [[ -f "$f" ]]; then
            SZ=$(stat -c%s "$f" 2>/dev/null || stat -f%z "$f")
            TOTAL_BYTES=$((TOTAL_BYTES + SZ))
        fi
        # Update progress bar
        TOTAL_MB=$((TOTAL_BYTES / 1024 / 1024))
        printf "\rCalculating total segment size: %4dMB in %4d files" $TOTAL_MB $COMPLETED_FILES
    done
    TOTAL_MB=$((TOTAL_BYTES / 1024 / 1024))
    echo "Calculating total segment size: $(TOTAL_MB)MB in $COMPLETED_FILES files"  
    echo "Already downloaded: $(TOTAL_MB)MB in $COMPLETED_FILES files."
else
    echo "Starting fresh download..."
    echo "0" > "$STATE_FILE"
fi

# 2) Determine playlist URL (cache on first run)
if [[ -f "$PLAYLIST_CACHE" ]]; then
    PLAYLIST_URL=$(<"$PLAYLIST_CACHE")
    echo "Using cached playlist: $PLAYLIST_URL"
else
    echo "Fetching playlist..."
    MASTER_CONTENT=$(curl -s "$URL" | tr -d '\r')
    if grep -q "#EXT-X-STREAM-INF" <<<"$MASTER_CONTENT"; then
        echo "Detected master playlist. Available resolutions:"
        declare -a res_array url_array; idx=0
        while IFS= read -r line; do
            line=${line//$'\r'/}
            if [[ $line == \#EXT-X-STREAM-INF* ]]; then
                res_array[idx]=$(sed -nE 's/.*RESOLUTION=([^,]*).*/\1/p' <<<"$line")
                read -r next_line
                url_array[idx]=${next_line//$'\r'/}
                idx=$((idx+1))
            fi
        done <<<"$MASTER_CONTENT"
        for i in "${!res_array[@]}"; do
            echo "  $((i+1)): ${res_array[i]}"
        done
        read -p "Enter your choice: " choice
        if ! [[ "$choice" =~ ^[0-9]+$ ]] || (( choice<1 || choice>${#res_array[@]} )); then
            echo "Invalid choice."; exit 1
        fi
        sel=$((choice-1))
        PLAYLIST_URL="${url_array[sel]}"
        # Resolve relative
        if [[ "$PLAYLIST_URL" != http* ]]; then
            if [[ "$PLAYLIST_URL" == /* ]]; then
                BASE=$(sed -E 's|(https?://[^/]+).*|\1|' <<<"$URL")
                PLAYLIST_URL="$BASE$PLAYLIST_URL"
            else
                PLAYLIST_URL="$(dirname "$URL")/$PLAYLIST_URL"
            fi
        fi
    else
        PLAYLIST_URL="$URL"
    fi
    echo "$PLAYLIST_URL" > "$PLAYLIST_CACHE"
    echo "Playlist set to: $PLAYLIST_URL"
fi

# 3) Fetch TS URLs (Used mainly for total count, download loop handles order based on playlist)
TS_URLS=$(curl -s "$PLAYLIST_URL" | tr -d '\r' | grep -v '^#')
TOTAL_FILES=$(wc -l <<<"$TS_URLS")
echo "Found $TOTAL_FILES TS files in playlist."

# Check if ffprobe is installed
if ! command -v ffprobe &> /dev/null; then
    echo "Error: ffprobe is not installed. It is required to verify segments."
    echo "Please install ffmpeg (which includes ffprobe)."
    exit 1
fi

# 4) Download loop
# The download loop will create files named _part_1.ts, _part_2.ts, etc.
# The order is handled by processing the TS_URLS in sequence.
CURRENT_FILE=0
for TS in $TS_URLS; do
    # make absolute if needed
    if [[ "$TS" != http* ]]; then
        if [[ "$TS" == /* ]]; then
            BASE=$(sed -E 's|(https?://[^/]+).*|\1|' <<<"$PLAYLIST_URL")
            TS="$BASE$TS"
        else
            TS="$(dirname "$PLAYLIST_URL")/$TS"
        fi
    fi
    CURRENT_FILE=$((CURRENT_FILE+1))
    OUT="$TMP_DIR/${OUTPUT_NAME}_part_${CURRENT_FILE}.ts"
    if (( CURRENT_FILE <= COMPLETED_FILES )); then
        printf "\rSkipping %4d/%4d (already have it)" $CURRENT_FILE $TOTAL_FILES
        # Even if skipping download, ensure the file exists for later ffprobe check
        if [[ ! -f "$OUT" ]]; then
             echo -e "\nWarning: Skipping download for segment $CURRENT_FILE, but file '$OUT' does not exist. It will be skipped in concatenation."
        fi
        continue
    fi
    # download with retries
    echo -e "\nDownloading segment $CURRENT_FILE/$TOTAL_FILES..."
    for ((a=1; a<=MAX_RETRIES; a++)); do
        curl -s "$TS" -o "$OUT" && [[ -s "$OUT" ]] && break
        if [[ $a -eq $MAX_RETRIES ]]; then
            echo -e "\nFailed to download segment $CURRENT_FILE: $TS"
            # Do NOT update state file for failed download
            # The file might still be created (empty or partial), which ffprobe will catch.
        else
            echo "Retry $a for segment $CURRENT_FILE..."
            sleep 2 # wait a bit before retrying
        fi
    done

    # Update progress and state file only if download was attempted and successful (file exists and is not empty)
    if [[ -f "$OUT" && -s "$OUT" ]]; then
         SZ=$(stat -c%s "$OUT" 2>/dev/null || stat -f%z "$OUT")
         TOTAL_BYTES=$((TOTAL_BYTES+SZ))
         printf "\rProgress: %3d%% | %4d/%4d | Last: %4dKB | Total: %4dMB" \
           $((CURRENT_FILE*100/TOTAL_FILES)) $CURRENT_FILE $TOTAL_FILES $((SZ/1024)) $((TOTAL_BYTES/1024/1024))
         echo "$CURRENT_FILE" > "$STATE_FILE"
    else
         # If download failed or resulted in empty file, report it and don't update state/total
         echo -e "\nWarning: Segment $CURRENT_FILE download failed or resulted in an empty file."
         # ffprobe check later will handle this missing/invalid file.
    fi
done
echo

# 5) Concat & merge
echo "Combining segments..."
pushd "$TMP_DIR" >/dev/null

# Create a properly versionâ€sorted concat list, skipping problematic files
> concat_list.txt
problematic_files=() # Array to store names of problematic files

echo "Verifying segment files by filename order before creating concat list..."

# Use ls -1v to get the list of segment files in version-sorted order
# The glob expansion ${OUTPUT_NAME}_part_*.ts will list files like
# _part_1.ts, _part_2.ts, ..., _part_10.ts, etc.
# ls -1v sorts these correctly numerically.
# We use a loop over the output of ls -1v
# Using 'while read -r seg' with 'ls -1v' handles filenames with spaces correctly.
find_command="ls -1v ${OUTPUT_NAME}_part_*.ts"
if ! eval "$find_command" > /dev/null 2>&1; then
    echo "Error: No segment files found matching pattern '${OUTPUT_NAME}_part_*.ts' in $TMP_DIR."
    popd >/dev/null
    # 6) Cleanup (Optional)
    read -p "Delete temp dir ($TMP_DIR)? (y/N): " resp
    if [[ "$resp" =~ ^[Yy]$ ]]; then
        rm -rf "$TMP_DIR"
        echo "Cleaned up."
    else
        echo "Temp retained at $TMP_DIR"
    fi
    echo "Done."
    exit 1
fi


eval "$find_command" | while read -r seg; do
    # Check if the file exists (should always be true since ls lists existing files, but good practice)
    # and is readable by ffprobe (basic validity check)
    if [[ -f "$seg" ]] && ffprobe -v error -i "$seg" >/dev/null 2>&1; then
        # File seems okay, add it to the concat list
        printf "\rAdded segment to list: '%s'\r\n" $seg
        echo "file '$seg'" >> concat_list.txt
    else
        # ffprobe failed or file doesn't exist, skip it.
        echo "Warning: Skipping problematic or missing segment '$seg'"
        problematic_files+=("$(basename "$seg")") # Add base name to the list of skipped files
    fi
done


# Check if concat_list.txt is empty after verification
if [ ! -s concat_list.txt ]; then
    echo "Error: No valid TS files found to concatenate after verification."
    # Optional: Print the list of problematic files if any were found
    if [ ${#problematic_files[@]} -gt 0 ]; then
        echo "Problematic files skipped:"
        printf " - %s\n" "${problematic_files[@]}"
    fi
    popd >/dev/null
    # 6) Cleanup (Optional)
    read -p "Delete temp dir ($TMP_DIR)? (y/N): " resp
    if [[ "$resp" =~ ^[Yy]$ ]]; then
        rm -rf "$TMP_DIR"
        echo "Cleaned up."
    else
        echo "Temp retained at $TMP_DIR"
    fi
    echo "Done."
    exit 1
fi

# Now merge:
echo "Concatenating verified segments..."
# Check if problematic files were skipped and report
if [ ${#problematic_files[@]} -gt 0 ]; then
    echo "Skipped ${#problematic_files[@]} problematic files during concatenation list creation."
    echo "Skipped files: $(IFS=,; echo "${problematic_files[*]}")"
fi

ffmpeg -y -f concat -safe 0 \
    -i concat_list.txt \
    -c copy "../${OUTPUT_FILENAME}"

# Check ffmpeg exit status
FFMPEG_EXIT_STATUS=$?
popd >/dev/null

if [ $FFMPEG_EXIT_STATUS -eq 0 ]; then
    echo "Conversion finished successfully: $OUTPUT_PATH"
else
    echo "Error: FFmpeg concatenation failed with exit status $FFMPEG_EXIT_STATUS."
    echo "The output file might be incomplete or corrupted due to skipped segments or other FFmpeg issues."
fi


# 6) Cleanup
read -p "Delete temp dir ($TMP_DIR)? (y/N): " resp
if [[ "$resp" =~ ^[Yy]$ ]]; then
    rm -rf "$TMP_DIR"
    echo "Cleaned up."
else
    echo "Temp retained at $TMP_DIR"
fi

echo "Done."
